{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Conv2D, Input, MaxPool2D, UpSampling2D, Concatenate, Conv2DTranspose\n",
    "from keras.layers import Activation, Reshape, Dropout\n",
    "from keras.layers import AtrousConvolution2D, Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "from keras import regularizers\n",
    "\n",
    "import tensorflow as tf \n",
    "\n",
    "from scipy.misc import imresize\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "from keras.preprocessing.image import array_to_img , img_to_array , load_img ,ImageDataGenerator \n",
    "\n",
    "from subprocess import check_output\n",
    "#print (check_output([\"ls\", \"../myproject\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"train/\"\n",
    "mask_dir = \"train_masks/\"\n",
    "all_images = os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4070\n"
     ]
    }
   ],
   "source": [
    "train_images, validation_images = train_test_split(all_images, train_size=0.8, test_size=0.2)\n",
    "print len(train_images)\n",
    "#content_image=Image.open('train/fc5f1a3a66cf_06.jpg')\n",
    "#content_image.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grey2rgb_2(img):\n",
    "    new_img=np.array(list(img)*3)\n",
    "    new_img=new_img.reshape(img.shape[0],img.shape[1],3)\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9f4a528590>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9f4a5ba290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def grey2rgb(img):\n",
    "    new_img = []\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            new_img.append(list(img[i][j])*3)\n",
    "    new_img = np.array(new_img).reshape(img.shape[0], img.shape[1], 3)\n",
    "    return new_img\n",
    "\n",
    "\n",
    "# generator that we will use to read the data from the directory\n",
    "def data_gen_small(data_dir, mask_dir, images, batch_size, dims):\n",
    "        \"\"\"\n",
    "        data_dir: where the actual images are kept\n",
    "        mask_dir: where the actual masks are kept\n",
    "        images: the filenames of the images we want to generate batches from\n",
    "        batch_size: self explanatory\n",
    "        dims: the dimensions in which we want to rescale our images\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            batch = np.random.choice(np.arange(len(images)), batch_size)\n",
    "            imgs = []\n",
    "            labels = []\n",
    "            for i in batch:\n",
    "                # images\n",
    "                original_img = load_img(data_dir + images[i])\n",
    "                resized_img = imresize(original_img, dims+[3])\n",
    "                array_img = img_to_array(resized_img)/255\n",
    "                imgs.append(array_img)\n",
    "                \n",
    "                # masks\n",
    "                original_mask = load_img(mask_dir + images[i].split(\".\")[0] + '_mask.gif')\n",
    "                resized_mask = imresize(original_mask,[dims[0]/8,dims[1]/8,3])\n",
    "                array_mask = img_to_array(resized_mask)/255\n",
    "                labels.append(array_mask[:, :, 0])\n",
    "            imgs = np.array(imgs)\n",
    "            labels = np.array(labels)\n",
    "            #print labels\n",
    "            yield imgs, labels.reshape(-1, dims[0]/8, dims[1]/8, 1)\n",
    "\n",
    "# example use\n",
    "train_gen = data_gen_small(data_dir, mask_dir, train_images, 5, [128, 128])\n",
    "img, msk = next(train_gen)\n",
    "\n",
    "plt.imshow(img[0])\n",
    "plt.imshow(grey2rgb(msk[0]), alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def down(input_layers,filters,pool=True):\n",
    "    conv1=Conv2D(filters,(2,2),padding=\"same\",activation='relu')(input_layers)\n",
    "    residual = Conv2D(filters, (3, 3), padding='same', activation='relu')(conv1)\n",
    "    if pool:\n",
    "        max_pool = MaxPool2D()(residual)\n",
    "        return max_pool, residual\n",
    "    else:\n",
    "        return residual\n",
    "\n",
    "def up(input_layer, residual, filters):\n",
    "    filters=int(filters)\n",
    "    upsample = UpSampling2D()(input_layer)\n",
    "    upconv = Conv2D(filters, kernel_size=(2, 2), padding=\"same\")(upsample)\n",
    "    concat = Concatenate(axis=3)([residual, upconv])\n",
    "    conv1 = Conv2D(filters, (3, 3), padding='same', activation='relu')(concat)\n",
    "    conv2 = Conv2D(filters, (3, 3), padding='same', activation='relu')(conv1)\n",
    "    return conv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_frontend(input_width, input_height):\n",
    "    model = Sequential()\n",
    "    # model.add(ZeroPadding2D((1, 1), input_shape=(input_width, input_height, 3)))\n",
    "    model.add(Convolution2D(64,(3,3),padding='same', activation='relu', name='conv1_1', input_shape=(input_width, input_height, 3)))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(Convolution2D(128,(3,3), padding='same',activation='relu', name='conv2_1'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(Convolution2D(256,(3,3),padding='same',activation='relu', name='conv3_1'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Convolution2D(512,(3,3), padding='same',activation='relu', name='conv4_1'))\n",
    "\n",
    "    # Compared to the original VGG16, we skip the next 2 MaxPool layers,\n",
    "    # and go ahead with dilated convolutional layers instead\n",
    "\n",
    "    model.add(AtrousConvolution2D(512, 3, 3, atrous_rate=(2, 2), activation='relu', name='conv5_1'))\n",
    "    #model.add(AtrousConvolution2D(512, 3, 3, atrous_rate=(2, 2), activation='relu', name='conv5_2'))\n",
    "    model.add(AtrousConvolution2D(512, 3, 3, atrous_rate=(2, 2), activation='relu', name='conv5_3'))\n",
    "\n",
    "    # Compared to the VGG16, we replace the FC layer with a convolution\n",
    "\n",
    "    model.add(AtrousConvolution2D(1024,3,3, atrous_rate=(2,2), activation='relu', name='fc6'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(1024, 1, 1, activation='relu', name='fc7'))\n",
    "    model.add(Dropout(0.5))\n",
    "    # Note: this layer has linear activations, not ReLU\n",
    "    model.add(Convolution2D(21, 1, 1, activation='linear', name='fc-final'))\n",
    "\n",
    "    # model.layers[-1].output_shape == (None, 16, 16, 21)\n",
    "    return model\n",
    "\n",
    "\n",
    "def add_softmax(model):\n",
    "    \"\"\" Append the softmax layers to the frontend or frontend + context net. \"\"\"\n",
    "    # The softmax layer doesn't work on the (width, height, channel)\n",
    "    # shape, so we reshape to (width*height, channel) first.\n",
    "    # https://github.com/fchollet/keras/issues/1169\n",
    "    _, curr_width, curr_height, curr_channels = model.layers[-1].output_shape\n",
    "\n",
    "    model.add(Reshape((curr_width * curr_height, curr_channels)))\n",
    "    model.add(Activation('softmax'))\n",
    "    # Technically, we need another Reshape here to reshape to 2d, but TF\n",
    "    # the complains when batch_size > 1. We're just going to reshape in numpy.\n",
    "    # model.add(Reshape((curr_width, curr_height, curr_channels)))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def add_context(model):\n",
    "    \"\"\" Append the context layers to the frontend. \"\"\"\n",
    "    model.add(ZeroPadding2D(padding=(33, 33)))\n",
    "    model.add(Convolution2D(42, 3, 3, activation='relu', name='ct_conv1_1'))\n",
    "    model.add(Convolution2D(42, 3, 3, activation='relu', name='ct_conv1_2'))\n",
    "    model.add(AtrousConvolution2D(84, 3, 3, atrous_rate=(2, 2), activation='relu', name='ct_conv2_1'))\n",
    "    model.add(AtrousConvolution2D(168, 3, 3, atrous_rate=(4, 4), activation='relu', name='ct_conv3_1'))\n",
    "    model.add(AtrousConvolution2D(336, 3, 3, atrous_rate=(8, 8), activation='relu', name='ct_conv4_1'))\n",
    "    model.add(AtrousConvolution2D(672, 3, 3, atrous_rate=(16, 16), activation='relu', name='ct_conv5_1'))\n",
    "    model.add(Convolution2D(672, 3, 3, activation='relu', name='ct_fc1'))\n",
    "    model.add(Convolution2D(21, 1, 1, name='ct_final'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 64)      832       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 64, 128)       32896     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 256)       131328    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 16, 16, 512)       524800    \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 16, 16, 1024)      4719616   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 16, 16, 1)         1025      \n",
      "=================================================================\n",
      "Total params: 15,624,321\n",
      "Trainable params: 15,624,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Make a custom U-nets implementation.\n",
    "filters = 64\n",
    "input_layer = Input(shape = [128, 128, 3])\n",
    "layers = [input_layer]\n",
    "residuals = []\n",
    "\n",
    "# Down 1, 128\n",
    "d1, res1 = down(input_layer, filters)\n",
    "residuals.append(res1)\n",
    "\n",
    "filters *= 2\n",
    "\n",
    "# Down 2, 64\n",
    "d2, res2 = down(d1, filters)\n",
    "residuals.append(res2)\n",
    "\n",
    "filters *= 2\n",
    "\n",
    "# Down 3, 32\n",
    "d3, res3 = down(d2, filters)\n",
    "residuals.append(res3)\n",
    "\n",
    "filters *= 2\n",
    "\n",
    "# Down 4, 16\n",
    "d5 = down(d3, filters, pool=False)\n",
    "\n",
    "atr1=Conv2D(512,(3,3),dilation_rate=(2, 2),activation='relu',padding='same')(d5)\n",
    "atr2=Conv2D(512,(3,3),dilation_rate=(2, 2),activation='relu',padding='same')(atr1)\n",
    "atr3=Conv2D(512,(3,3),dilation_rate=(2, 2),activation='relu',padding='same')(atr2)\n",
    "\n",
    "fc6=Conv2D(1024,(3,3),dilation_rate=(2, 2),activation='relu',padding='same')(atr3)\n",
    "\n",
    "fc7=Dropout(0.5)(fc6)\n",
    "\n",
    "\n",
    "\n",
    "out = Conv2D(filters=1, kernel_size=(1, 1), activation=\"sigmoid\")(fc7)\n",
    "\n",
    "model = Model(input_layer, out)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1_1 (Conv2D)             (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2_1 (Conv2D)             (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv3_1 (Conv2D)             (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv4_1 (Conv2D)             (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv5_1 (Conv2D)             (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv5_3 (Conv2D)             (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "fc6 (Conv2D)                 (None, 4, 4, 1024)        4719616   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "fc7 (Conv2D)                 (None, 4, 4, 1024)        1049600   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "fc-final (Conv2D)            (None, 4, 4, 21)          21525     \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 16, 21)            0         \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16, 21)            0         \n",
      "=================================================================\n",
      "Total params: 12,061,333\n",
      "Trainable params: 12,061,333\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saurabh/myproject/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), activation=\"relu\", name=\"fc7\")`\n",
      "/home/saurabh/myproject/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:29: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(21, (1, 1), activation=\"linear\", name=\"fc-final\")`\n"
     ]
    }
   ],
   "source": [
    "input_width=128\n",
    "input_height=input_width\n",
    "input_layer = Input(shape = [128, 128, 3])\n",
    "model = get_frontend(input_width, input_height)\n",
    "\n",
    "model = add_softmax(model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "def dice_coeff(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1 - dice_coeff(y_true, y_pred)\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "100/100 [==============================] - 64s - loss: 0.5724 - dice_coeff: 0.6970    \n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 53s - loss: 0.3090 - dice_coeff: 0.8355    \n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 53s - loss: 0.2745 - dice_coeff: 0.8539    \n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 49s - loss: 0.2479 - dice_coeff: 0.8697    \n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 51s - loss: 0.2376 - dice_coeff: 0.8734    \n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 53s - loss: 0.2281 - dice_coeff: 0.8776    \n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 52s - loss: 0.2220 - dice_coeff: 0.8818    \n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 48s - loss: 0.2200 - dice_coeff: 0.8823    \n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 50s - loss: 0.2166 - dice_coeff: 0.8843    \n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 53s - loss: 0.2160 - dice_coeff: 0.8849    \n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 51s - loss: 0.2140 - dice_coeff: 0.8853    \n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 48s - loss: 0.2116 - dice_coeff: 0.8861    \n",
      "Epoch 13/30\n",
      " 16/100 [===>..........................] - ETA: 40s - loss: 0.2108 - dice_coeff: 0.8845"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f6ac73719256>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mbce_dice_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdice_coeff\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/saurabh/myproject/tensorflow/local/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saurabh/myproject/tensorflow/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, initial_epoch)\u001b[0m\n\u001b[1;32m   1807\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1808\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1809\u001b[0;31m                     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1811\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saurabh/myproject/tensorflow/local/lib/python2.7/site-packages/keras/utils/data_utils.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    634\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(1e-4), loss= bce_dice_loss, metrics=[dice_coeff])\n",
    "model.fit_generator(train_gen, steps_per_epoch=100,epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#accuracy = model.evaluate(test_x, test_y, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_gen = data_gen_small(data_dir, mask_dir, validation_images, 5, [128, 128])\n",
    "img, msk = next(train_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.evaluate_generator(validation_gen,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_frontend(input_width, input_height):\n",
    "    model = Sequential()\n",
    "    # model.add(ZeroPadding2D((1, 1), input_shape=(input_width, input_height, 3)))\n",
    "    model.add(Convolution2D(64,(3,3), activation='relu', name='conv1_1', input_shape=(input_width, input_height, 3)))\n",
    "    model.add(Convolution2D(64,(3,3), 3, activation='relu', name='conv1_2'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(Convolution2D(128,(3,3), activation='relu', name='conv2_1'))\n",
    "    model.add(Convolution2D(128,(3,3), 3, activation='relu', name='conv2_2'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(Convolution2D(256,(3,3), activation='relu', name='conv3_1'))\n",
    "    model.add(Convolution2D(256, (3,3), activation='relu', name='conv3_2'))\n",
    "    model.add(Convolution2D(256, (3,3) , activation='relu', name='conv3_3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(Convolution2D(512,(3,3), activation='relu', name='conv4_1'))\n",
    "    model.add(Convolution2D(512,(3,3), activation='relu', name='conv4_2'))\n",
    "    model.add(Convolution2D(512,(3,3), activation='relu', name='conv4_3'))\n",
    "\n",
    "    # Compared to the original VGG16, we skip the next 2 MaxPool layers,\n",
    "    # and go ahead with dilated convolutional layers instead\n",
    "\n",
    "    model.add(AtrousConvolution2D(512, 3, 3, atrous_rate=(2, 2), activation='relu', name='conv5_1'))\n",
    "    model.add(AtrousConvolution2D(512, 3, 3, atrous_rate=(2, 2), activation='relu', name='conv5_2'))\n",
    "    model.add(AtrousConvolution2D(512, 3, 3, atrous_rate=(2, 2), activation='relu', name='conv5_3'))\n",
    "\n",
    "    # Compared to the VGG16, we replace the FC layer with a convolution\n",
    "\n",
    "    model.add(AtrousConvolution2D(4096, 7, 7, atrous_rate=(2, 2), activation='relu', name='fc6'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(4096, 1, 1, activation='relu', name='fc7'))\n",
    "    model.add(Dropout(0.5))\n",
    "    # Note: this layer has linear activations, not ReLU\n",
    "    model.add(Convolution2D(21, 1, 1, activation='linear', name='fc-final'))\n",
    "\n",
    "    # model.layers[-1].output_shape == (None, 16, 16, 21)\n",
    "    return model\n",
    "\n",
    "\n",
    "def add_softmax(model):\n",
    "    \"\"\" Append the softmax layers to the frontend or frontend + context net. \"\"\"\n",
    "    # The softmax layer doesn't work on the (width, height, channel)\n",
    "    # shape, so we reshape to (width*height, channel) first.\n",
    "    # https://github.com/fchollet/keras/issues/1169\n",
    "    _, curr_width, curr_height, curr_channels = model.layers[-1].output_shape\n",
    "\n",
    "    model.add(Reshape((curr_width * curr_height, curr_channels)))\n",
    "    model.add(Activation('softmax'))\n",
    "    # Technically, we need another Reshape here to reshape to 2d, but TF\n",
    "    # the complains when batch_size > 1. We're just going to reshape in numpy.\n",
    "    # model.add(Reshape((curr_width, curr_height, curr_channels)))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def add_context(model):\n",
    "    \"\"\" Append the context layers to the frontend. \"\"\"\n",
    "    model.add(ZeroPadding2D(padding=(33, 33)))\n",
    "    model.add(Convolution2D(42, 3, 3, activation='relu', name='ct_conv1_1'))\n",
    "    model.add(Convolution2D(42, 3, 3, activation='relu', name='ct_conv1_2'))\n",
    "    model.add(AtrousConvolution2D(84, 3, 3, atrous_rate=(2, 2), activation='relu', name='ct_conv2_1'))\n",
    "    model.add(AtrousConvolution2D(168, 3, 3, atrous_rate=(4, 4), activation='relu', name='ct_conv3_1'))\n",
    "    model.add(AtrousConvolution2D(336, 3, 3, atrous_rate=(8, 8), activation='relu', name='ct_conv4_1'))\n",
    "    model.add(AtrousConvolution2D(672, 3, 3, atrous_rate=(16, 16), activation='relu', name='ct_conv5_1'))\n",
    "    model.add(Convolution2D(672, 3, 3, activation='relu', name='ct_fc1'))\n",
    "    model.add(Convolution2D(21, 1, 1, name='ct_final'))\n",
    "\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
